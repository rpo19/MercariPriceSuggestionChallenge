{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_oO4ZyYU00Y"
   },
   "source": [
    "### Mercari Price \n",
    "The files consist of a list of product listings. These files are tab-delimited.\n",
    "\n",
    "Fields:\n",
    "- train_id or test_id - the id of the listing\n",
    "\n",
    "- name - the title of the listing. Note that we have cleaned the data to remove text that look like prices (e.g. $20) to avoid  leakage. These removed prices are represented as [rm]\n",
    "\n",
    "- item_condition_id - the condition of the items provided by the seller\n",
    "\n",
    "- category_name - category of the listing\n",
    "\n",
    "- brand_name\n",
    "\n",
    "- price - the price that the item was sold for. This is the target variable that you will predict. The unit is USD. This column doesn't exist in test.tsv since that is what you will predict.\n",
    "\n",
    "- shipping - 1 if shipping fee is paid by seller and 0 by buyer\n",
    "\n",
    "- item_description - the full description of the item. Note that we have cleaned the data to remove text that look like prices (e.g. $20) to avoid leakage. These removed prices are represented as [rm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XZWiRNuUU00w"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Input, Embedding, Concatenate, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s4RfjlP1VCjh"
   },
   "outputs": [],
   "source": [
    "tqdm_notebook.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oXCUW4PtU00k",
    "outputId": "f3e389f2-cda2-4f17-831c-7c3fc2b84b64"
   },
   "outputs": [],
   "source": [
    "# check if in colab\n",
    "RunningInCOLAB = 'google.colab' in str(get_ipython())\n",
    "if RunningInCOLAB:\n",
    "    print(\"Running in colab\")\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive', force_remount=True)\n",
    "    colab_root = '/content/drive'\n",
    "    root_dir = \"/content/gdrive/My Drive/\"\n",
    "    base_dir = root_dir + 'project-mercari-price/'\n",
    "    if not os.path.isdir(base_dir):\n",
    "        os.mkdir(base_dir)\n",
    "else:\n",
    "    root_dir= os.getcwd()\n",
    "    base_dir = root_dir\n",
    "    \n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1JFkFCLXU00m",
    "outputId": "3ee79bbf-3081-4664-9bb5-88c38c7dff69"
   },
   "outputs": [],
   "source": [
    "dataset_downloaded_path = os.path.join(base_dir, \"dataset_downloaded.ignore\")\n",
    "dataset_downloaded = os.path.isfile(dataset_downloaded_path)\n",
    "dataset_downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "24RhWXO6U00p"
   },
   "outputs": [],
   "source": [
    "if not dataset_downloaded:\n",
    "  # install kaggle to download dataset\n",
    "  ! pip install kaggle python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xw0Fy7K5U00r"
   },
   "outputs": [],
   "source": [
    "# set to True if you want to save kaggle credentials into a .env file\n",
    "persist_credentials = False\n",
    "\n",
    "if not dataset_downloaded:\n",
    "  # create .env file containing KAGGLE_USER and KAGGLE_KEY\n",
    "    kaggle_env = os.path.join(base_dir, '.env')\n",
    "    if not os.path.isfile(kaggle_env):\n",
    "        with open(kaggle_env, 'w') as envfile:\n",
    "            kaggle_user = input(\"Insert kaggle username\")\n",
    "            kaggle_key = input(\"Insert kaggle key; generate one from kaggle account\")\n",
    "        if persist_credentials:\n",
    "            envfile.write(f\"\"\"\n",
    "            KAGGLE_USERNAME={kaggle_user}\n",
    "            KAGGLE_KEY={kaggle_key}\n",
    "            \"\"\")\n",
    "\n",
    "        # set env vars\n",
    "        os.environ[\"KAGGLE_USERNAME\"] = kaggle_user\n",
    "        os.environ[\"KAGGLE_KEY\"] = kaggle_key\n",
    "\n",
    "        del kaggle_user\n",
    "        del kaggle_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7zJ0iRN9U00u"
   },
   "outputs": [],
   "source": [
    "if not dataset_downloaded:\n",
    "  # loading env vars if .env file exists\n",
    "    if os.path.isfile(kaggle_env):\n",
    "        from dotenv import load_dotenv\n",
    "        load_dotenv(dotenv_path=kaggle_env)\n",
    "    print(os.environ.get(\"KAGGLE_USERNAME\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SP-mPFo-U00v"
   },
   "outputs": [],
   "source": [
    "if not dataset_downloaded:\n",
    "    # download and extract dataset\n",
    "    ! kaggle competitions download -c mercari-price-suggestion-challenge\n",
    "\n",
    "    # create file so that we know we already downloaded\n",
    "    with open(dataset_downloaded_path, 'w') as dd_file:\n",
    "        dataset_downloaded = True\n",
    "        dd_file.write(\"\")\n",
    "\n",
    "    print('cwd: ', os.getcwd())\n",
    "    \n",
    "    os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cpAT2yysVsRm"
   },
   "outputs": [],
   "source": [
    "if not dataset_downloaded:\n",
    "    ! 7z x train.tsv.7z\n",
    "    ! 7z x test.tsv.7z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rbwBGoI1VplX",
    "outputId": "cb4e2a9b-5d85-4bdb-f302-6e07ea367ec3"
   },
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 665
    },
    "id": "j5Vg17INU00x",
    "outputId": "f1133ee2-63a2-442f-b9d7-188602b66411"
   },
   "outputs": [],
   "source": [
    "dtypes={\n",
    "    'name': 'string',\n",
    "    'item_condition_id': 'byte',\n",
    "    'category_name': 'string',\n",
    "    'brand_name': 'string',\n",
    "    'price': 'float',\n",
    "    'shipping': 'boolean',\n",
    "    'item_description': 'string'\n",
    "}\n",
    "data = pd.read_csv(\"train.tsv\", sep='\\t', dtype=dtypes)\n",
    "data = data.drop(columns=[\"train_id\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DmtH5d_GU00z",
    "outputId": "20065221-82dd-4596-979a-190cdad273b5"
   },
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9TY3K5euCtuA",
    "outputId": "ce50ddaa-8d06-4f74-c4b3-edae3665c58e"
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rvujMFFXCxL8",
    "outputId": "b4125c9b-48b9-42fd-f6f9-20fe8c324c4c"
   },
   "outputs": [],
   "source": [
    "for column in data.columns:\n",
    "    print(\"number of null value in {} : {}\".format(column,data[column].isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jUBsIEJqC0cg",
    "outputId": "a1d6941c-37fa-4996-c76b-8018f11a9251"
   },
   "outputs": [],
   "source": [
    "data = data[data[\"item_description\"].notna()]\n",
    "data[\"brand_name\"] = data[\"brand_name\"].fillna(value=\"NA\")\n",
    "data[\"category_name\"] = data[\"category_name\"].fillna(value=\"NA\")\n",
    "# see warnings -> inplace?\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_list(l):\n",
    "    return  [item for sublist in l for item in sublist]\n",
    "\n",
    "\n",
    "def plot_common_tokens(tokens, title, n=20):\n",
    "    sentences = (list(itertools.chain(tokens)))\n",
    "    flat_sentences = flat_list(sentences)\n",
    "    counts = Counter(flat_sentences)\n",
    "    #print(counts.most_common(30))\n",
    "    common_words = [word[0] for word in counts.most_common(n)]\n",
    "    common_counts = [word[1] for word in counts.most_common(n)]\n",
    "    fig = plt.figure(figsize=(18,6))\n",
    "    sns.barplot(x=common_words, y=common_counts)\n",
    "    plt.title(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_common_tokens(data[\"item_description_tokens\"], \"Most Common Tokens from Descriptions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['name', 'item_condition_id', 'category_name', 'brand_name',\n",
    "       'shipping','item_description']]\n",
    "y = data['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1000)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.2, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTokens(data, tokenizer=None, dataFit=None, num_words=5000):\n",
    "    if dataFit is None:\n",
    "        dataFit = data\n",
    "        \n",
    "    if tokenizer is None:\n",
    "        tokenizer = Tokenizer(num_words=num_words)\n",
    "        tokenizer.fit_on_texts(dataFit)\n",
    "    \n",
    "    tokens = tokenizer.texts_to_sequences(data)\n",
    "    return tokens, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"item_description_t\"], tokenizers[\"item_description\"] = getTokens(X_train[\"item_description\"])\n",
    "X_train[\"name_t\"], tokenizers[\"name\"] = getTokens(X_train[\"name\"])\n",
    "#X_train[\"brand_name_t\"], tokenizers[\"brand_name\"] = getTokens(X_train[\"brand_name\"])\n",
    "#X_train[\"category_name_t\"], tokenizers[\"category_name\"] = getTokens(X_train[\"category_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"item_description_t\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_le = preprocessing.LabelEncoder()\n",
    "cat_le.fit(X_train[\"category_name\"])\n",
    "\n",
    "X_train[\"category_name_l\"] = cat_le.transform(X_train[\"category_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_le = preprocessing.LabelEncoder()\n",
    "brand_le.fit(X_train[\"brand_name\"])\n",
    "\n",
    "X_train[\"brand_name_l\"] = brand_le.transform(X_train[\"brand_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenizers[\"item_description\"].word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unknown values !!! now -> crash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.loc[995196, [\"name\", \"name_t\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5W0A95PQEDb_",
    "outputId": "89c64f8e-9f13-4925-99dc-deb120a2b33b"
   },
   "outputs": [],
   "source": [
    "desc_vocab_size = len(tokenizers['item_description'].word_index) + 1\n",
    "print(desc_vocab_size)\n",
    "\n",
    "name_vocab_size = len(tokenizers['name'].word_index) + 1\n",
    "print(name_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"item_description_t\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = X_train[\"item_description_t\"]\n",
    "padded = pad_sequences(test, padding='post', maxlen=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y40ov-ULHtla",
    "outputId": "93d701d0-0a30-4f27-d1bf-73179ef281d9"
   },
   "outputs": [],
   "source": [
    "\n",
    "maxlen = 100\n",
    "\n",
    "inputDesc_train= pad_sequences(X_train[\"item_description_t\"],\n",
    "                                                  padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputName_train = pad_sequences(X_train[\"name_t\"], padding='post', maxlen=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SLcxUX3ESGDo"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "msle = tf.keras.losses.MeanSquaredLogarithmicError()\n",
    "\n",
    "def root_mean_squared_logarithmic_error(y_true, y_pred):\n",
    "    return K.sqrt(msle(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[[\"item_condition_id\", \"category_name_l\", \"brand_name_l\", \"shipping\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_vocab_size = 880000\n",
    "desc_vocab_size=1500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel():\n",
    "    inputA = Input(shape=(4,))\n",
    "    Ad = Dense(4, activation='relu')(inputA)\n",
    "    \n",
    "    inputName = Input(shape=(20,))\n",
    "    Ne = Embedding(input_dim=name_vocab_size, output_dim=16, input_length=20)(inputName)\n",
    "    Nf = Flatten()(Ne)\n",
    "    Nd = Dense(8, activation='relu')(Nf)\n",
    "    \n",
    "    inputDesc = Input(shape=(100,))\n",
    "    De = Embedding(input_dim=desc_vocab_size, output_dim=32, input_length=100)(inputDesc)\n",
    "    Df = Flatten()(De)\n",
    "    Dd = Dense(16, activation='relu')(Df)\n",
    "    \n",
    "    concat = Concatenate()([Ad, Nd, Dd])\n",
    "    \n",
    "    x = Dense(32, activation='relu')(concat)\n",
    "    x = Dense(1, activation='linear')(x)\n",
    "    \n",
    "    model = Model(inputs=[inputA, inputName, inputDesc], outputs=x)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = getModel()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1-rcb1aLIHPX",
    "outputId": "afa152e0-094f-4311-9f86-5233c4acffab"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError(), 'mean_squared_logarithmic_error', root_mean_squared_logarithmic_error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputA_train = X_train[[\"item_condition_id\", \"category_name_l\", \"brand_name_l\", \"shipping\"]].values.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputA_train.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y2m3WcI-JWcP",
    "outputId": "be101128-acfc-48f2-d343-07dfabc2591d"
   },
   "outputs": [],
   "source": [
    "history = model.fit(x=[inputA_train, inputName_train, inputDesc_train], y=y_train,\n",
    "                    epochs=5,\n",
    "                    verbose=True,\n",
    "                    #validation_data=(X_validation, y_validation),\n",
    "                    batch_size=256)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MercariPrice.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
